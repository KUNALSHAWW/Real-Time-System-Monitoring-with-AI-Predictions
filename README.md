# ğŸ¥ Real-Time System Health Monitor with AI Predictions

<div align="center">

![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.9+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Status](https://img.shields.io/badge/status-production--ready-success.svg)
![Streamlit](https://img.shields.io/badge/streamlit-1.28+-FF4B4B.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688.svg)

**Enterprise-grade system monitoring platform with AI-powered anomaly detection, intelligent fix suggestions, and predictive analytics. Built with user-friendly UI for both technical and non-technical users.**

[Features](#-key-features) â€¢ [Quick Start](#-quick-start) â€¢ [Screenshots](#-screenshots) â€¢ [API](#-api-reference) â€¢ [Architecture](#-architecture)

---

### ğŸ‘¨â€ğŸ’» Developed By

**Kunal Shaw**  
ğŸ“ Computer Science Student | ğŸš€ Full-Stack Developer | ğŸ¤– AI/ML Enthusiast

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/kunal-kumar-shaw-443999205)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/KUNALSHAWW)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:cs23b1039@iiitr.ac.in)

</div>

---

## ğŸ¯ Overview

A **production-ready**, **open-source** system health monitoring platform designed for **everyone** - from DevOps engineers to business managers. Features an intuitive, responsive UI with smooth animations, intelligent notifications, and AI-powered insights that make system monitoring accessible to non-technical users.

### ğŸŒŸ What Makes This Different?

- ğŸ¨ **User-Friendly Interface**: Beautiful, responsive UI with smooth animations - no technical knowledge required
- ğŸ“ **Beginner-Friendly**: Interactive welcome tour, helpful tooltips, and plain-language explanations
- ğŸ“± **Fully Responsive**: Works seamlessly on desktop, tablet, and mobile devices
- ğŸ”” **Smart Notifications**: Multi-channel alerts (Email, In-App) with intelligent escalation
- ğŸ¤– **AI-Powered Intelligence**: Automated root cause analysis and fix recommendations
- ğŸ“Š **Predictive Analytics**: Forecast issues before they impact your system
- âš¡ **Real-Time Updates**: Live metrics with configurable refresh rates (5-60 seconds)
- ğŸ¯ **Customizable Thresholds**: Set your own alert levels with easy-to-use sliders
- ğŸŒ **Multi-LLM Support**: GROQ (cloud), Ollama (local), Hugging Face integration
- ğŸ” **Enterprise Security**: JWT authentication, RBAC, input sanitization, CSRF protection
- ğŸ“ˆ **Production-Ready**: Docker/Kubernetes ready, horizontal scaling, high availability

### ğŸª Perfect For

- **System Administrators**: Monitor infrastructure health with intelligent alerts
- **DevOps Engineers**: Proactive issue detection with AI-powered fix suggestions
- **Business Managers**: High-level health overview without technical complexity
- **IT Teams**: Collaborative incident management with role-based access
- **Developers**: API-first design with comprehensive documentation

## âœ¨ Key Features

### ï¿½ Beautiful & Intuitive UI (app_final.py)

- **Smooth Animations**: Fade-in effects, hover transitions, and pulse animations for alerts
- **Responsive Design**: Mobile-first approach that works on all screen sizes
- **Color-Coded Status**: Instant visual feedback with Green (Healthy), Yellow (Warning), Red (Critical)
- **Progress Bars**: Visual indicators for all metrics with smooth transitions
- **Welcome Tour**: First-time users get an interactive guided introduction
- **Personalized Greeting**: "Good morning/afternoon/evening" based on time of day
- **Interactive Help**: Tooltips and help sections throughout the interface
- **Dark Theme**: Professional dark theme optimized for long monitoring sessions

### ğŸ¯ Core Monitoring Capabilities

- **Real-Time Metrics Dashboard**
  - CPU, Memory, Disk, Network monitoring with live updates
  - Configurable refresh intervals (5 seconds to 1 hour)
  - Historical data retention and trend analysis
  - Animated charts with multiple view types (Line, Area, Bar)

- **Smart Health Indicators**
  - Three-tier status system (Healthy, Warning, Critical)
  - Automatic threshold detection
  - Visual progress bars with percentage indicators
  - Component-wise health scoring

### ğŸ”” Intelligent Notification System

- **Multi-Channel Alerts**
  - ğŸ“§ **Email Notifications**: SMTP integration with customizable templates
  - ğŸ’¬ **In-App Alerts**: Real-time notification center with unread badges
  - ğŸ”´ **Visual Indicators**: Animated pulse effects for critical alerts
  - ğŸ¯ **Priority-Based Routing**: Severity-based notification delivery

- **Notification Center Features**
  - Unread notification counter
  - Timestamp tracking
  - Mark as read/unread
  - Clear all notifications
  - Last 50 notifications preserved
  - Severity-based color coding (Info, Warning, Critical)

### ğŸ¤– AI-Powered Intelligence

- **Automated Fix Suggestions Engine** â­ NEW
  - Context-specific troubleshooting guides
  - 4-tier remediation strategy:
    - ğŸ” **Root Causes**: Why did this happen?
    - âš¡ **Immediate Actions**: What to do RIGHT NOW
    - ğŸ› ï¸ **Short-term Fixes**: Solutions for today/week
    - ğŸ¯ **Long-term Solutions**: Permanent fixes to implement
  - Ready-to-run terminal commands
  - Prevention strategies to avoid recurrence

- **Multi-LLM Integration**
  - **GROQ**: Ultra-fast cloud inference (70B models in <1s)
  - **Ollama**: Local LLM runtime (privacy-first, no API costs)
  - **Hugging Face**: Access to 100K+ pre-trained models
  - **Automatic Fallback**: Seamless provider switching on failure

- **Natural Language Analysis**
  - Query your system in plain English
  - Automated incident summaries
  - Root cause analysis
  - Impact assessment

### ğŸ“Š Predictive Analytics

- **Simple Forecasting**
  - Linear trend analysis for CPU usage
  - Multi-step ahead predictions
  - Confidence scoring
  - Risk assessment (Low, Medium, High)

- **Proactive Alerting**
  - Predict when thresholds will be exceeded
  - Early warning system
  - Capacity planning recommendations

### âš™ï¸ User-Friendly Settings

- **Profile Management**
  - Set display name for personalized experience
  - Email configuration with validation
  - Quick save functionality

- **Custom Alert Thresholds**
  - Easy-to-use sliders for each metric
  - CPU: 50-100% (default 80%)
  - Memory: 50-100% (default 75%)
  - Disk: 50-100% (default 80%)
  - Network: 100-5000 MB (default 1000 MB)
  - One-click reset to defaults

- **Notification Preferences**
  - Toggle email alerts on/off
  - Toggle in-app notifications on/off
  - Test notification button
  - SMTP configuration guide

- **Refresh Settings**
  - Auto-refresh toggle
  - Refresh interval slider (5-60 seconds)
  - Manual refresh button
  - Real-time update counter

### ğŸ› ï¸ Developer-Friendly

- **RESTful API**
  - OpenAPI/Swagger documentation
  - JWT authentication
  - Rate limiting
  - Comprehensive error handling

- **Modern Tech Stack**
  - FastAPI (async/await)
  - Streamlit (reactive UI)
  - Redis (caching & state)
  - PostgreSQL/SQLite
  - Docker/Kubernetes ready

### ğŸª Non-Technical User Features

- **Plain Language Interface**: No jargon, simple explanations everywhere
- **Visual Indicators**: Icons and colors instead of complex numbers
- **Quick Actions**: Big, clear buttons for common tasks
- **Guided Workflows**: Step-by-step processes for complex operations
- **Help & Support**: Built-in documentation and keyboard shortcuts
- **Export Ready**: Download data for reports (coming soon)

## ğŸ“¸ Screenshots

<div align="center">

![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.9+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Status](https://img.shields.io/badge/status-production--ready-success.svg)
![Streamlit](https://img.shields.io/badge/streamlit-1.28+-FF4B4B.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688.svg)

**Enterprise-grade system monitoring platform with AI-powered anomaly detection, intelligent fix suggestions, and predictive analytics. Built with user-friendly UI for both technical and non-technical[...]

[Features](#-key-features) â€¢ [Quick Start](#-quick-start) â€¢ [Screenshots](#-screenshots) â€¢ [API](#-api-reference) â€¢ [Architecture](#-architecture)

---

### ğŸ‘¨â€ğŸ’» Developed By

**Kunal Shaw**  
ğŸ“ Computer Science Student | ğŸš€ Full-Stack Developer | ğŸ¤– AI/ML Enthusiast

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/kunal-kumar-shaw-443999205)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/KUNALSHAWW)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:cs23b1039@iiitr.ac.in)

</div>

---

## ğŸ—ï¸ System Architecture

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ENTERPRISE SYSTEM HEALTH MONITOR v2.0                       â”‚
â”‚                          Built by Kunal Shaw                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Load Balancer  â”‚
                              â”‚   (Nginx/HAProxy)â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                    â”‚                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Streamlit     â”‚  â”‚   FastAPI      â”‚  â”‚   WebSocket    â”‚
         â”‚  Dashboard UI   â”‚  â”‚   REST API     â”‚  â”‚   Real-time    â”‚
         â”‚ (app_final.py)  â”‚  â”‚  (Port 8000)   â”‚  â”‚   Updates      â”‚
         â”‚  (Port 8501)    â”‚  â”‚                â”‚  â”‚                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                   â”‚                    â”‚
                  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
                  â”‚    â”‚   Notification System     â”‚      â”‚
                  â”‚    â”‚   - Email (SMTP)          â”‚      â”‚
                  â”‚    â”‚   - In-App Alerts         â”‚      â”‚
                  â”‚    â”‚   - Priority Routing      â”‚      â”‚
                  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
                  â”‚                                        â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   State Manager         â”‚
                         â”‚   Redis + Local Cache   â”‚
                         â”‚   - Session Management  â”‚
                         â”‚   - Metrics Buffer      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                       â”‚                       â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  ML Engine      â”‚    â”‚  Data Pipeline  â”‚    â”‚  Fix Engine     â”‚
     â”‚  - Anomaly Det. â”‚    â”‚  - Collection   â”‚    â”‚  - Root Cause   â”‚
     â”‚  - Forecasting  â”‚    â”‚  - Processing   â”‚    â”‚  - Remediation  â”‚
     â”‚  - LLM Analysis â”‚    â”‚  - Buffering    â”‚    â”‚  - Prevention   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                      â”‚                       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      Database Layer             â”‚
                    â”‚  - SQLite (dev)                 â”‚
                    â”‚  - PostgreSQL (prod)            â”‚
                    â”‚  - Redis (cache/state)          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           EXTERNAL INTEGRATIONS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GROQ API  â”‚  Ollama  â”‚  Hugging Face  â”‚  SMTP  â”‚  Email Alerts  â”‚  Logs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

### ğŸ¯ Key Components

#### Frontend Layer (app_final.py)
- **Enhanced Streamlit UI** with smooth animations and responsive design
- **Session State Management** for user preferences and notifications
- **Real-time Updates** with configurable refresh intervals
- **Interactive Charts** with Plotly (Line, Area, Bar views)
- **Notification Center** with unread badges and filtering
- **Settings Panel** with easy-to-use sliders and toggles

#### Backend Layer (FastAPI)
- **RESTful API** with async/await for high performance
- **JWT Authentication** for secure access
- **WebSocket Support** for real-time metric streaming
- **Rate Limiting** to prevent abuse
- **CORS Configuration** for cross-origin requests

#### Intelligence Layer
- **Multi-LLM Support**: GROQ, Ollama, Hugging Face integration
- **Anomaly Detection**: Isolation Forest, LOF algorithms
- **Fix Suggestions**: Context-aware remediation guides
- **Forecasting**: Simple linear trend analysis

#### Data Layer
- **SQLite** for development (zero configuration)
- **PostgreSQL** for production (scalable, ACID compliant)
- **Redis** for caching and session state (optional)
- **Deque Buffer** for in-memory metrics history (last 100 points)

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+** (3.11 recommended for best performance)
- **Docker & Docker Compose** (optional but recommended)
- **PostgreSQL 13+** or **SQLite** (for development)
- **Redis 7+** (optional, for production)
- **4GB+ RAM** (8GB+ recommended for ML models)

### One-Command Installation

```bash
# Clone repository
git clone https://github.com/yourusername/system-monitoring-ai.git
cd system-monitoring-ai

# Run setup script
chmod +x setup.sh
./setup.sh

# Or on Windows
.\setup.ps1
```

### Manual Installation

#### 1. Clone and Setup Environment

```bash
git clone https://github.com/yourusername/system-monitoring-ai.git
cd "real time system monitoring with AI predictions"

# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (macOS/Linux)
source venv/bin/activate
```

#### 2. Install Dependencies

```bash
# Install all dependencies at once
pip install -r backend/requirements.txt \
            -r frontend/requirements.txt \
            -r ml_engine/requirements.txt

# Or install individually
cd backend && pip install -r requirements.txt
cd ../frontend && pip install -r requirements.txt
cd ../ml_engine && pip install -r requirements.txt
```

#### 3. Configuration

Create `.env` file in project root:

```bash
cp .env.example .env
```

Edit `.env` with your configuration:

```env
# ============================================================================
# REQUIRED - API KEYS
# ============================================================================

# GROQ (Get from: https://console.groq.com/keys)
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxx

# Hugging Face (Get from: https://huggingface.co/settings/tokens)
HUGGINGFACE_API_TOKEN=hf_xxxxxxxxxxxxxxxxxxxx

# ============================================================================
# OPTIONAL - Advanced Features
# ============================================================================

# OpenAI (fallback)
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx

# Ollama (local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================

# SQLite (Development)
DATABASE_URL=sqlite:///./system_monitoring.db

# PostgreSQL (Production)
# DATABASE_URL=postgresql://user:password@localhost:5432/system_monitoring

# Redis (Production - optional for dev)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# ============================================================================
# APPLICATION SETTINGS
# ============================================================================

ENVIRONMENT=development
DEBUG=True
SECRET_KEY=your-secret-key-change-in-production
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000

# CORS (frontend URL)
CORS_ORIGINS=["http://localhost:8501"]

# ============================================================================
# NOTIFICATION SETTINGS
# ============================================================================

# Email/SMTP
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# Slack
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# PagerDuty
PAGERDUTY_API_KEY=your-api-key
PAGERDUTY_SERVICE_KEY=your-service-key
```

#### 4. Initialize Database

```bash
# The app will auto-create SQLite database on first run
# For PostgreSQL, create database first:
createdb system_monitoring

# Run migrations (if applicable)
cd backend
alembic upgrade head
```

### 5ï¸âƒ£ Start the Application

**Option A: Using the Enhanced UI (Recommended)**

```powershell
# Terminal 1: Start Backend API
cd backend
python main.py
# ğŸŒ API: http://localhost:8000
# ğŸ“š Docs: http://localhost:8000/docs

# Terminal 2: Start Enhanced Dashboard
cd frontend
streamlit run app_final.py
# ğŸ¨ Dashboard: http://localhost:8501
```

**Option B: Docker Compose (Production)**

```bash
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

### ğŸ‰ Access Your Platform

- **ğŸ¨ Enhanced Dashboard**: http://localhost:8501 (User-friendly UI)
- **ğŸ“š API Documentation**: http://localhost:8000/docs (Interactive Swagger)
- **ğŸ“– API Redoc**: http://localhost:8000/redoc (Alternative docs)
- **â¤ï¸ Health Check**: http://localhost:8000/health (System status)

### ğŸ¯ First-Time Setup Guide

1. **Open the Dashboard**
   - Navigate to http://localhost:8501
   - You'll see a welcome tour with balloons ğŸˆ
   - Click "Got it! Let's start monitoring"

2. **Set Up Your Profile**
   - Open sidebar â†’ "âš™ï¸ Quick Settings"
   - Enter your display name (e.g., "John Doe")
   - Enter your email address (validated automatically)
   - âœ… Valid email = green checkmark

3. **Configure Notifications**
   - Toggle "ğŸ“§ Email" for email alerts
   - Toggle "ğŸ’¬ In-App" for dashboard notifications
   - Click "ğŸ§ª Test Notifications" to verify setup

4. **Customize Alert Thresholds**
   - Go to "Settings" â†’ "ğŸ“Š Thresholds" tab
   - Use sliders to set custom alert levels:
     - CPU: 80% (default)
     - Memory: 75% (default)
     - Disk: 80% (default)
     - Network: 1000 MB (default)
   - Click "ğŸ’¾ Save Thresholds"

5. **Explore Features**
   - **Dashboard**: Real-time health overview
   - **Metrics**: Detailed performance data
   - **Alerts**: View alert history and management
   - **Predictions**: Forecast future trends
   - **Settings**: Customize your experience

6. **Test the System**
   - Watch metrics update automatically
   - Check notification center (sidebar)
   - Try different chart types
   - Adjust refresh interval

### ğŸ¨ UI Features Highlights

| Feature | Description | How to Access |
|---------|-------------|---------------|
| ğŸ¨ **Smooth Animations** | Fade-in effects, hover transitions | Automatic on all pages |
| ğŸ“Š **Progress Bars** | Visual metric indicators | Dashboard cards |
| ğŸ”” **Notification Badge** | Unread alert counter | Sidebar notification center |
| ğŸŒˆ **Color-Coded Status** | Green/Yellow/Red indicators | All metric cards |
| ğŸ“ˆ **Chart Views** | Line, Area, Bar charts | Metrics page dropdown |
| âš™ï¸ **Easy Settings** | Sliders and toggles | Settings page, all tabs |
| ğŸ‘‹ **Welcome Tour** | First-time user guide | Auto-shows on first visit |
| ğŸ”„ **Quick Refresh** | Manual update button | Dashboard header |

## ğŸ“š Core Features Guide

### 1ï¸âƒ£ Real-Time Dashboard

Monitor system health at a glance:

```
ğŸ“Š Dashboard Overview
â”œâ”€â”€ Key Metrics Cards (CPU, Memory, Disk, Network)
â”œâ”€â”€ Real-time Charts (auto-refresh)
â”œâ”€â”€ Component Health Scores
â”œâ”€â”€ Recent Alerts with Quick Fix Buttons
â””â”€â”€ Critical Alert Banner (when issues detected)
```

**Quick Fix Feature**: Click ğŸ”§ button next to any alert for instant troubleshooting steps

### 2ï¸âƒ£ Intelligent Incident Management

Navigate to **Incidents** page for comprehensive issue resolution:

```
ğŸš¨ Incident Details
â”œâ”€â”€ ğŸ” Root Causes - Possible reasons for the issue
â”œâ”€â”€ âš¡ Immediate Actions - What to do RIGHT NOW
â”œâ”€â”€ ğŸ› ï¸ Short-term Fixes - Temporary solutions (today/week)
â”œâ”€â”€ ğŸ¯ Long-term Solutions - Permanent fixes to implement
â”œâ”€â”€ ğŸ’» Commands - Copy-paste terminal commands
â””â”€â”€ ğŸ›¡ï¸ Prevention - Avoid future occurrences
```

**Example: CPU Usage Alert**

When CPU exceeds threshold, you get:
- **Immediate**: `top -o %CPU` to find high-CPU processes
- **Short-term**: Implement rate limiting, enable throttling
- **Long-term**: Migrate to auto-scaling (AWS/K8s)
- **Prevention**: Set 70% alerts, implement APM monitoring

### 3ï¸âƒ£ Predictive Analytics

**Predictions** page offers:

- **Prophet Forecasting**: Seasonal trend analysis
- **ARIMA Models**: Auto-regressive predictions
- **Multi-horizon**: 6h, 12h, 24h, 48h forecasts
- **Anomaly Risk Scoring**: Probability of future issues

```python
# API Usage
GET /api/v1/predictions/forecast/cpu?hours=24
```

### 4ï¸âƒ£ AI-Powered Analysis

**AI Analysis** page provides:

- Natural language queries about your system
- Automated incident summaries
- Root cause analysis
- Recommended actions

```python
# Example Query
"Why is memory usage increasing on server-01?"

# AI Response
- Memory leak in application XYZ
- Suggested fix: Restart service, check logs
- Long-term: Update to version 2.0 with fix
```

### 5ï¸âƒ£ Advanced Features

#### Custom Metrics

Add your own metrics via Admin Panel:

```python
# Register custom metric plugin
from metric_plugin import MetricPlugin

class CustomCPUMetric(MetricPlugin):
    def collect(self):
        # Your collection logic
        return cpu_percentage
    
    def visualize(self, data):
        # Custom visualization
        pass
```

#### Role-Based Access Control (RBAC)

Three permission levels:
- **Viewer**: Read-only access
- **Operator**: Can acknowledge alerts, create incidents
- **Admin**: Full access including configuration

#### WebSocket Real-Time Updates

```javascript
// Connect to WebSocket
const ws = new WebSocket('ws://localhost:8000/ws');

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    updateDashboard(data);
};
```

## ï¿½ API Reference

### Base URL

```
Development: http://localhost:8000/api/v1
Production:  https://api.youromain.com/api/v1
```

### Authentication

All API endpoints (except health checks) require JWT authentication:

```bash
# Login to get JWT token
curl -X POST http://localhost:8000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "admin", "password": "password"}'

# Response
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}

# Use token in subsequent requests
curl -X GET http://localhost:8000/api/v1/metrics/cpu \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

### Core Endpoints

#### Health & Status

```bash
# Health check (no auth required)
GET /health
Response: {"status": "healthy", "database": "connected", "redis": "connected"}

# Detailed system status
GET /api/v1/status
Response: {
  "uptime": "5d 3h 24m",
  "requests_today": 15234,
  "active_incidents": 3,
  "ml_models_loaded": true
}
```

#### Metrics Collection

```bash
# Get current CPU metrics
GET /api/v1/metrics/cpu
Response: {
  "value": 45.2,
  "timestamp": "2024-01-15T10:30:00Z",
  "threshold": 80,
  "status": "normal"
}

# Get memory metrics with history
GET /api/v1/metrics/memory?hours=24
Response: {
  "current": 65.5,
  "historical": [...],
  "trend": "increasing",
  "prediction_1h": 68.2
}

# Get all metrics (dashboard view)
GET /api/v1/metrics/all
Response: {
  "cpu": {"value": 45.2, "status": "normal"},
  "memory": {"value": 65.5, "status": "warning"},
  "disk": {"value": 78.3, "status": "warning"},
  "network": {"rx": 1245, "tx": 3456, "status": "normal"}
}
```

#### Anomaly Detection

```bash
# Get recent anomalies
GET /api/v1/anomalies/list?limit=50
Response: [
  {
    "id": "anom_123",
    "metric": "cpu_usage",
    "value": 95.5,
    "threshold": 80,
    "severity": "critical",
    "timestamp": "2024-01-15T10:30:00Z",
    "fix_suggestions": {
      "immediate_actions": ["Check top processes", "Review recent deployments"],
      "commands": ["top -o %CPU", "systemctl status"]
    }
  }
]

# Analyze specific metric for anomalies
POST /api/v1/anomalies/analyze
Body: {
  "metric": "cpu_usage",
  "data": [45.2, 50.1, 48.3, 92.5, 91.2],
  "algorithm": "isolation_forest"
}
Response: {
  "anomalies_detected": [92.5, 91.2],
  "anomaly_scores": [0.95, 0.92],
  "recommendations": "CPU spike detected. Check for runaway processes."
}
```

#### Intelligent Fix Suggestions

```bash
# Get fix suggestions for specific incident
GET /api/v1/incidents/{incident_id}/fixes
Response: {
  "incident_id": "inc_456",
  "metric": "cpu_usage",
  "value": 95.5,
  "fix_suggestions": {
    "root_causes": [
      "Memory leak in application",
      "Runaway background process",
      "Insufficient resources for workload"
    ],
    "immediate_actions": [
      "Identify top CPU processes: `top -o %CPU`",
      "Check recent deployments",
      "Review application logs"
    ],
    "short_term_fixes": [
      "Restart affected services",
      "Implement rate limiting",
      "Enable CPU throttling"
    ],
    "long_term_solutions": [
      "Migrate to auto-scaling infrastructure",
      "Optimize application code",
      "Implement horizontal scaling"
    ],
    "commands": [
      "top -o %CPU",
      "systemctl restart <service>",
      "kubectl scale deployment <name> --replicas=3"
    ],
    "preventive_measures": [
      "Set up 70% CPU alerts",
      "Implement APM monitoring",
      "Schedule regular resource reviews"
    ]
  }
}
```

#### Predictions & Forecasting

```bash
# Get CPU forecast
GET /api/v1/predictions/forecast/cpu?hours=24
Response: {
  "metric": "cpu_usage",
  "current": 45.2,
  "predictions": [
    {"timestamp": "2024-01-15T11:00:00Z", "value": 47.5, "confidence": 0.85},
    {"timestamp": "2024-01-15T12:00:00Z", "value": 52.1, "confidence": 0.82}
  ],
  "trend": "increasing",
  "anomaly_risk": 0.15
}

# Get anomaly risk score
GET /api/v1/predictions/anomaly-risk
Response: {
  "cpu": {"risk_score": 0.15, "severity": "low"},
  "memory": {"risk_score": 0.65, "severity": "medium"},
  "disk": {"risk_score": 0.85, "severity": "high"}
}
```

#### AI-Powered Analysis

```bash
# Query AI assistant
POST /api/v1/analysis/query
Body: {
  "question": "Why is memory usage increasing on server-01?",
  "llm_provider": "groq",
  "model": "llama2-70b-4096"
}
Response: {
  "answer": "Memory usage is increasing due to...",
  "root_causes": [...],
  "recommendations": [...],
  "confidence": 0.92,
  "sources": ["system_logs", "metrics_history"]
}

# Get incident summary
POST /api/v1/analysis/incident-summary
Body: {
  "incident_id": "inc_789",
  "include_fixes": true
}
Response: {
  "summary": "CPU spike detected at 10:30 UTC...",
  "impact": "High latency for users in US-East region",
  "duration": "15 minutes",
  "affected_services": ["web-api", "worker-queue"],
  "fix_applied": "Restarted worker-queue service",
  "prevention": "Implement auto-scaling triggers"
}
```

#### WebSocket Real-Time Updates

```javascript
// Connect to WebSocket for live metrics
const ws = new WebSocket('ws://localhost:8000/ws/metrics');

ws.onopen = () => {
    console.log('Connected to metrics stream');
    // Subscribe to specific metrics
    ws.send(JSON.stringify({
        action: 'subscribe',
        metrics: ['cpu', 'memory', 'disk']
    }));
};

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    console.log('Live metric update:', data);
    // {
    //   "metric": "cpu",
    //   "value": 45.2,
    //   "timestamp": "2024-01-15T10:30:00Z",
    //   "status": "normal",
    //   "anomaly_detected": false
    // }
    updateDashboard(data);
};

ws.onerror = (error) => {
    console.error('WebSocket error:', error);
};

ws.onclose = () => {
    console.log('Disconnected. Reconnecting...');
    setTimeout(() => connectWebSocket(), 5000);
};
```

### Response Codes

| Code | Description |
|------|-------------|
| 200 | Success |
| 201 | Created |
| 400 | Bad Request - Invalid parameters |
| 401 | Unauthorized - Missing or invalid token |
| 403 | Forbidden - Insufficient permissions |
| 404 | Not Found - Resource doesn't exist |
| 429 | Too Many Requests - Rate limit exceeded |
| 500 | Internal Server Error |
| 503 | Service Unavailable - Dependency failure |

### Rate Limiting

```
Default Limits:
- Authenticated: 1000 requests/hour
- Anonymous: 100 requests/hour
- WebSocket: 10 connections per IP

Headers:
X-RateLimit-Limit: 1000
X-RateLimit-Remaining: 847
X-RateLimit-Reset: 1642248000
```

## ğŸ—ï¸ Project Structure

```
real-time-system-monitoring-ai/
â”‚
â”œâ”€â”€ ğŸ“ backend/                      # FastAPI REST API & WebSocket Server
â”‚   â”œâ”€â”€ main.py                      # Application entry point
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile                   # Container build config
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ core/                     # Core business logic
â”‚   â”‚   â”œâ”€â”€ config.py                # Settings & environment variables
â”‚   â”‚   â”œâ”€â”€ database.py              # DB connection & session management
â”‚   â”‚   â”œâ”€â”€ logger.py                # Centralized logging
â”‚   â”‚   â”œâ”€â”€ notifications.py         # Email/Slack/PagerDuty alerts
â”‚   â”‚   â”œâ”€â”€ rbac.py                  # Role-based access control
â”‚   â”‚   â””â”€â”€ state_manager.py         # Redis cache + local fallback
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ routers/                  # API endpoints (grouped by feature)
â”‚   â”‚   â”œâ”€â”€ authentication.py        # JWT login/register/refresh
â”‚   â”‚   â”œâ”€â”€ system_metrics.py        # CPU/Memory/Disk/Network APIs
â”‚   â”‚   â”œâ”€â”€ anomaly_detection.py     # Anomaly analysis endpoints
â”‚   â”‚   â”œâ”€â”€ predictions.py           # Forecasting & risk scoring
â”‚   â”‚   â”œâ”€â”€ incidents.py             # Incident CRUD + fix suggestions
â”‚   â”‚   â”œâ”€â”€ ai_analysis.py           # LLM-powered insights
â”‚   â”‚   â””â”€â”€ websocket.py             # Real-time metric streaming
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ middleware/               # Request/response interceptors
â”‚   â”‚   â”œâ”€â”€ logging_middleware.py    # HTTP request logging
â”‚   â”‚   â””â”€â”€ error_handler.py         # Global exception handling
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ logs/                     # Application logs (auto-generated)
â”‚
â”œâ”€â”€ ğŸ“ frontend/                     # Streamlit Dashboard
â”‚   â”œâ”€â”€ app.py                       # Standard dashboard
â”‚   â”œâ”€â”€ app_enhanced.py              # ğŸš€ Enhanced with AI fix suggestions
â”‚   â”œâ”€â”€ requirements.txt             # UI dependencies
â”‚   â””â”€â”€ Dockerfile                   # Frontend container
â”‚
â”œâ”€â”€ ğŸ“ ml_engine/                    # Machine Learning & AI
â”‚   â”œâ”€â”€ anomaly_detector.py          # Isolation Forest, LOF, One-Class SVM
â”‚   â”œâ”€â”€ llm_manager.py               # GROQ/Ollama/HuggingFace integration
â”‚   â”œâ”€â”€ model_training.ipynb         # Jupyter notebook for experimentation
â”‚   â””â”€â”€ requirements.txt             # ML dependencies (torch, sklearn, prophet)
â”‚
â”œâ”€â”€ ğŸ“ data_pipeline/                # Data Collection & Processing
â”‚   â”œâ”€â”€ data_pipeline.py             # Async metric collection
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ security_audit.py            # Security scanning tool
â”‚   â””â”€â”€ test_ws_client.py            # WebSocket testing client
â”‚
â”œâ”€â”€ ğŸ“ docs/                         # Documentation
â”‚   â”œâ”€â”€ API_KEYS_SETUP.md            # How to get API keys
â”‚   â”œâ”€â”€ PRODUCTION_SETUP.md          # Production deployment guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md              # System design deep-dive
â”‚   â”œâ”€â”€ DEPLOYMENT_CHECKLIST.md      # Pre-deployment validation
â”‚   â””â”€â”€ ENHANCEMENT_SUMMARY.md       # Feature changelog
â”‚
â”œâ”€â”€ ğŸ“ infrastructure/               # DevOps & deployment (not shown in tree)
â”‚   â”œâ”€â”€ docker-compose.yml           # Multi-container orchestration
â”‚   â”œâ”€â”€ kubernetes/                  # K8s manifests
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â””â”€â”€ ingress.yaml
â”‚   â””â”€â”€ terraform/                   # IaC for cloud provisioning
â”‚
â”œâ”€â”€ .env.example                     # Environment template
â”œâ”€â”€ .env                             # âš ï¸ Your secrets (gitignored)
â”œâ”€â”€ README.md                        # ğŸ“– This file
â”œâ”€â”€ QUICKSTART.md                    # Fast setup guide
â””â”€â”€ LICENSE                          # MIT License

Key Files:
-----------
ğŸ”¥ app_enhanced.py          - Enhanced dashboard with AI-powered fix suggestions
ğŸ”¥ llm_manager.py           - Multi-LLM integration (GROQ/Ollama/HF)
ğŸ”¥ state_manager.py         - High-performance caching layer
ğŸ”¥ incidents.py (router)    - Intelligent incident management APIs
ğŸ”¥ anomaly_detector.py      - Production ML models for anomaly detection
```

### File Responsibilities

| File | Purpose | Key Functions |
|------|---------|---------------|
| `backend/main.py` | FastAPI app initialization | `lifespan()`, router registration, CORS setup |
| `frontend/app_enhanced.py` | Enhanced Streamlit UI | `get_fix_suggestions()`, incident management, AI chat |
| `ml_engine/llm_manager.py` | LLM abstraction layer | `smart_analyze()`, fallback logic, model selection |
| `ml_engine/anomaly_detector.py` | ML model training & inference | `fit()`, `predict()`, `get_anomaly_score()` |
| `backend/core/state_manager.py` | Distributed state management | `get()`, `set()`, TTL management, LRU caching |
| `backend/routers/incidents.py` | Incident API endpoints | `create_incident()`, `get_fix_suggestions()` |
| `data_pipeline/data_pipeline.py` | Async metric collection | `add_data_point()`, buffering, batch processing |

## ğŸ¤– AI & Machine Learning Features

### 1. Automated Fix Suggestions Engine

**How It Works:**

```python
# Triggered when anomaly detected
def get_fix_suggestions(metric_name: str, value: float, threshold: float):
    """
    Returns comprehensive troubleshooting guide:
    - Root causes (why did this happen?)
    - Immediate actions (what to do NOW?)
    - Short-term fixes (solutions for today/week)
    - Long-term solutions (permanent fixes)
    - Terminal commands (copy-paste ready)
    - Preventive measures (avoid future issues)
    """
    
    # Example for CPU spike
    if metric_name == "CPU" and value > threshold:
        return {
            "root_causes": [
                "Memory leak in application",
                "Runaway background process",
                "DDoS attack or traffic spike"
            ],
            "immediate_actions": [
                "Run `top -o %CPU` to identify process",
                "Check logs: `journalctl -xe --since '10 minutes ago'`",
                "Review recent deployments"
            ],
            "commands": [
                "top -o %CPU",
                "systemctl restart <service>",
                "kubectl scale deployment --replicas=3"
            ]
        }
```

**Supported Metrics:**
- âœ… CPU Usage
- âœ… Memory Usage
- âœ… Disk Space
- âœ… Network Latency
- âœ… Database Connections
- âœ… API Response Time
- âœ… Error Rates

### 2. Multi-LLM Integration

**Three-Tier Fallback Strategy:**

```
1. GROQ API (Primary)
   â”œâ”€ Speed: âš¡ ~500ms response
   â”œâ”€ Models: llama2-70b, mixtral-8x7b
   â””â”€ Cost: Free tier available

2. Ollama (Secondary - Local)
   â”œâ”€ Speed: ğŸ¢ ~2-5s response
   â”œâ”€ Models: llama2, mistral, neural-chat
   â””â”€ Cost: Free (only compute)

3. Hugging Face (Tertiary)
   â”œâ”€ Speed: ğŸƒ ~1-3s response
   â”œâ”€ Models: 100,000+ options
   â””â”€ Cost: Free (API limits apply)

4. OpenAI (Fallback)
   â”œâ”€ Speed: âš¡ ~800ms response
   â”œâ”€ Models: gpt-4, gpt-3.5-turbo
   â””â”€ Cost: Pay-per-token
```

**Usage Example:**

```python
from ml_engine.llm_manager import get_llm_manager

llm = get_llm_manager()

# Automatic provider selection with fallback
result = await llm.smart_analyze(
    "Why is memory usage spiking every night at 2 AM?",
    method="auto"  # Tries GROQ â†’ Ollama â†’ HF â†’ OpenAI
)

print(result["answer"])
# "The memory spike at 2 AM is likely caused by scheduled batch jobs..."
```

### 3. Anomaly Detection Models

**Algorithm Selection Guide:**

| Algorithm | Speed | Accuracy | Use Case |
|-----------|-------|----------|----------|
| **Isolation Forest** | âš¡âš¡âš¡ | â­â­â­ | Production real-time detection |
| **Local Outlier Factor** | âš¡âš¡ | â­â­â­â­ | Complex pattern recognition |
| **One-Class SVM** | âš¡ | â­â­â­â­â­ | High-precision critical systems |

**Training & Deployment:**

```python
from ml_engine.anomaly_detector import get_anomaly_detector

# Initialize detector for CPU metric
detector = get_anomaly_detector(
    metric_name="cpu_usage",
    algorithm="isolation_forest",
    contamination=0.1  # Expect 10% anomalies
)

# Train on historical data
historical_data = get_last_30_days_cpu_data()
detector.fit(historical_data)

# Real-time prediction
is_anomaly, score = detector.predict_single(current_cpu_value)

if is_anomaly:
    # Trigger alert + fix suggestions
    alert_with_fixes(metric="CPU", value=current_cpu_value, score=score)
```

### 4. Forecasting & Predictions

**Supported Models:**

- **Prophet (Facebook)**: Seasonal patterns, holidays, trend changes
- **ARIMA**: Auto-regressive time-series forecasting
- **LSTM (PyTorch)**: Deep learning for complex patterns

**Example: 24-Hour CPU Forecast**

```python
from ml_engine.predictor import forecast_metric

predictions = forecast_metric(
    metric="cpu_usage",
    hours=24,
    model="prophet"
)

# predictions = [
#   {"timestamp": "2024-01-15T11:00", "value": 47.5, "confidence": 0.85},
#   {"timestamp": "2024-01-15T12:00", "value": 52.3, "confidence": 0.82},
#   ...
# ]

# Predict anomaly risk
if predictions[12]["value"] > 80:
    send_proactive_alert("CPU will exceed 80% in 12 hours")
```

## ğŸ” Security & Authentication

### JWT Authentication

```python
# Login to get token
POST /api/v1/auth/login
Body: {"username": "admin", "password": "SecurePass123!"}

Response: {
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer",
  "expires_in": 3600
}

# Use token in requests
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

### Role-Based Access Control (RBAC)

| Role | Permissions | Use Case |
|------|-------------|----------|
| **Viewer** | Read metrics, view dashboards | Stakeholders, managers |
| **Operator** | + Acknowledge alerts, create incidents | On-call engineers |
| **Admin** | + Configure thresholds, manage users | DevOps leads |

### API Key Management

```bash
# Generate API key for external integrations
POST /api/v1/auth/api-keys
Body: {"name": "Grafana Integration", "permissions": ["read:metrics"]}

Response: {
  "api_key": "sm_live_1234567890abcdef",
  "permissions": ["read:metrics"],
  "expires_at": "2025-01-15T00:00:00Z"
}

# Use in requests
curl -H "X-API-Key: sm_live_1234567890abcdef" \
  http://localhost:8000/api/v1/metrics/cpu
```

### Security Best Practices

âœ… **Implemented:**
- JWT token expiration (1 hour)
- Password hashing with bcrypt
- HTTPS enforcement (production)
- CORS protection
- Rate limiting (1000 req/hour)
- SQL injection prevention (SQLAlchemy ORM)
- XSS protection (FastAPI auto-escaping)

âš ï¸ **Recommended for Production:**
- Enable 2FA for admin accounts
- Rotate secrets monthly
- Use Vault for secret management
- Implement IP whitelisting
- Enable audit logging
- Set up intrusion detection

## ğŸš€ Deployment Guide

### Docker Deployment (Recommended)

#### Single-Container Deployment

```bash
# Build image
docker build -t system-monitoring:latest .

# Run with environment file
docker run -d \
  --name system-monitor \
  -p 8000:8000 \
  -p 8501:8501 \
  --env-file .env \
  -v $(pwd)/logs:/app/logs \
  system-monitoring:latest

# Check logs
docker logs -f system-monitor
```

#### Docker Compose (Multi-Container)

```bash
# Start all services
docker-compose up -d

# Scale backend instances
docker-compose up -d --scale backend=3

# View service status
docker-compose ps

# View logs for specific service
docker-compose logs -f backend

# Stop services
docker-compose down

# Stop and remove volumes (fresh start)
docker-compose down -v
```

**docker-compose.yml Structure:**

```yaml
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: system_monitoring
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data

  # FastAPI Backend
  backend:
    build: ./backend
    depends_on:
      - postgres
      - redis
    environment:
      DATABASE_URL: postgresql://admin:${DB_PASSWORD}@postgres:5432/system_monitoring
      REDIS_HOST: redis
    ports:
      - "8000:8000"
    restart: unless-stopped

  # Streamlit Frontend
  frontend:
    build: ./frontend
    depends_on:
      - backend
    environment:
      BACKEND_URL: http://backend:8000
    ports:
      - "8501:8501"
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```

### Kubernetes Deployment

#### Deploy to Cluster

```bash
# Create namespace
kubectl create namespace monitoring

# Apply configurations
kubectl apply -f infrastructure/kubernetes/ -n monitoring

# Check deployment status
kubectl get pods -n monitoring
kubectl get services -n monitoring

# View logs
kubectl logs -f deployment/monitoring-backend -n monitoring

# Scale deployment
kubectl scale deployment monitoring-backend --replicas=5 -n monitoring
```

#### Key Kubernetes Resources

**deployment.yaml:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: monitoring-backend
  namespace: monitoring
spec:
  replicas: 3
  selector:
    matchLabels:
      app: monitoring-backend
  template:
    metadata:
      labels:
        app: monitoring-backend
    spec:
      containers:
      - name: backend
        image: your-registry/system-monitoring:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```

**service.yaml:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: monitoring-backend
  namespace: monitoring
spec:
  type: LoadBalancer
  selector:
    app: monitoring-backend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
```

**ingress.yaml (with HTTPS):**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: monitoring-ingress
  namespace: monitoring
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - monitoring.yourdomain.com
    secretName: monitoring-tls
  rules:
  - host: monitoring.yourdomain.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: monitoring-backend
            port:
              number: 80
      - path: /
        pathType: Prefix
        backend:
          service:
            name: monitoring-frontend
            port:
              number: 8501
```

### Cloud Provider Deployments

#### AWS Elastic Beanstalk

```bash
# Initialize EB CLI
eb init -p python-3.11 system-monitoring

# Create environment
eb create production-env \
  --instance-type t3.medium \
  --envvars DATABASE_URL=$DATABASE_URL,GROQ_API_KEY=$GROQ_API_KEY

# Deploy updates
eb deploy

# View logs
eb logs
```

#### Google Cloud Run

```bash
# Build and push to GCR
gcloud builds submit --tag gcr.io/PROJECT_ID/system-monitoring

# Deploy to Cloud Run
gcloud run deploy system-monitoring \
  --image gcr.io/PROJECT_ID/system-monitoring \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --set-env-vars DATABASE_URL=$DATABASE_URL

# Get service URL
gcloud run services describe system-monitoring --region us-central1
```

#### Azure Container Instances

```bash
# Create resource group
az group create --name monitoring-rg --location eastus

# Deploy container
az container create \
  --resource-group monitoring-rg \
  --name system-monitoring \
  --image your-registry/system-monitoring:latest \
  --cpu 2 \
  --memory 4 \
  --ports 8000 8501 \
  --environment-variables \
    DATABASE_URL=$DATABASE_URL \
    GROQ_API_KEY=$GROQ_API_KEY

# Get public IP
az container show --resource-group monitoring-rg --name system-monitoring --query ipAddress.ip
```

### Production Checklist

#### Pre-Deployment

- [ ] **Environment Variables**
  - [ ] `DEBUG=False` set
  - [ ] Strong `SECRET_KEY` generated
  - [ ] All API keys configured
  - [ ] Database URL points to production DB

- [ ] **Security**
  - [ ] HTTPS/TLS certificates configured
  - [ ] CORS origins restricted
  - [ ] Rate limiting enabled
  - [ ] API keys rotated
  - [ ] Firewall rules configured

- [ ] **Database**
  - [ ] Backup strategy implemented
  - [ ] Connection pooling configured
  - [ ] Indexes created
  - [ ] Migration scripts tested

- [ ] **Monitoring**
  - [ ] Health checks configured
  - [ ] Log aggregation setup (CloudWatch/Datadog)
  - [ ] Error tracking (Sentry)
  - [ ] Uptime monitoring (PingDom)

- [ ] **Performance**
  - [ ] CDN configured for static assets
  - [ ] Response caching enabled
  - [ ] Database query optimization
  - [ ] Load balancer configured

#### Post-Deployment

- [ ] **Smoke Tests**
  - [ ] Health endpoint responding: `curl https://your-domain.com/health`
  - [ ] API documentation accessible: `/docs`
  - [ ] Dashboard loads correctly
  - [ ] WebSocket connections working

- [ ] **Load Testing**
  ```bash
  # Use Locust or k6
  k6 run --vus 100 --duration 30s load_test.js
  ```

- [ ] **Security Scan**
  ```bash
  # Run OWASP ZAP or similar
  python scripts/security_audit.py
  ```

- [ ] **Monitoring Verification**
  - [ ] Logs appearing in aggregator
  - [ ] Metrics being collected
  - [ ] Alerts configured and tested

### Scaling Strategies

#### Horizontal Scaling

```bash
# Docker Compose
docker-compose up -d --scale backend=5

# Kubernetes
kubectl scale deployment monitoring-backend --replicas=10

# AWS Auto Scaling
aws autoscaling set-desired-capacity \
  --auto-scaling-group-name monitoring-asg \
  --desired-capacity 5
```

#### Vertical Scaling

```yaml
# Update Kubernetes resources
resources:
  requests:
    memory: "512Mi"  # Up from 256Mi
    cpu: "500m"      # Up from 250m
  limits:
    memory: "1Gi"    # Up from 512Mi
    cpu: "1000m"     # Up from 500m
```

#### Auto-Scaling Configuration

```yaml
# Horizontal Pod Autoscaler (K8s)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: monitoring-backend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: monitoring-backend
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### Backup & Disaster Recovery

#### Database Backups

```bash
# PostgreSQL automated backups (cron job)
0 2 * * * pg_dump -U admin system_monitoring | gzip > backup_$(date +\%Y\%m\%d).sql.gz

# Restore from backup
gunzip backup_20240115.sql.gz
psql -U admin system_monitoring < backup_20240115.sql
```

#### Redis Persistence

```bash
# Enable RDB snapshots (redis.conf)
save 900 1       # Save after 900s if 1 key changed
save 300 10      # Save after 300s if 10 keys changed
save 60 10000    # Save after 60s if 10000 keys changed

# Enable AOF (append-only file)
appendonly yes
appendfsync everysec
```

### Monitoring & Observability

#### Prometheus Metrics

```python
# Add to backend/main.py
from prometheus_client import Counter, Histogram, generate_latest

# Metrics
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests')
REQUEST_LATENCY = Histogram('http_request_duration_seconds', 'HTTP request latency')

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

#### Grafana Dashboards

```json
{
  "dashboard": {
    "title": "System Monitoring Dashboard",
    "panels": [
      {
        "title": "API Requests/sec",
        "targets": [{"expr": "rate(http_requests_total[5m])"}]
      },
      {
        "title": "CPU Usage",
        "targets": [{"expr": "avg(cpu_usage)"}]
      }
    ]
  }
}
```

### Troubleshooting Production Issues

#### Check Service Health

```bash
# All containers running?
docker-compose ps

# Pod status
kubectl get pods -n monitoring

# Service endpoints
kubectl get endpoints -n monitoring
```

#### View Logs

```bash
# Docker
docker-compose logs -f --tail=100 backend

# Kubernetes
kubectl logs -f deployment/monitoring-backend -n monitoring --tail=100

# Filter for errors
kubectl logs deployment/monitoring-backend -n monitoring | grep ERROR
```

#### Database Connection Issues

```bash
# Test connection from pod
kubectl exec -it deployment/monitoring-backend -n monitoring -- bash
psql $DATABASE_URL -c "SELECT 1"

# Check connection pool
kubectl exec deployment/monitoring-backend -n monitoring -- \
  python -c "from backend.core.database import engine; print(engine.pool.status())"
```

#### High CPU/Memory Usage

```bash
# Top resource consumers
docker stats

# Kubernetes resource usage
kubectl top pods -n monitoring

# Profile Python app
kubectl exec deployment/monitoring-backend -n monitoring -- \
  python -m cProfile -s cumtime backend/main.py
```

## ğŸ§ª Testing

### Unit Tests

```bash
# Backend API tests
cd backend
pytest tests/ -v --cov --cov-report=html

# Coverage report at: backend/htmlcov/index.html
```

### Integration Tests

```bash
# Test end-to-end flows
pytest tests/integration/ -v

# Test WebSocket connections
python scripts/test_ws_client.py
```

### Load Testing

```bash
# Install Locust
pip install locust

# Run load test
locust -f tests/load_test.py --host=http://localhost:8000

# Or use k6
k6 run --vus 100 --duration 30s tests/k6_load_test.js
```

**Example Load Test (Locust):**

```python
from locust import HttpUser, task, between

class SystemMonitorUser(HttpUser):
    wait_time = between(1, 3)
    
    @task(3)
    def get_cpu_metrics(self):
        self.client.get("/api/v1/metrics/cpu")
    
    @task(2)
    def get_memory_metrics(self):
        self.client.get("/api/v1/metrics/memory")
    
    @task(1)
    def create_incident(self):
        self.client.post("/api/v1/incidents/create", json={
            "title": "Test Incident",
            "severity": "medium"
        })
```

### Security Testing

```bash
# Run security audit
python scripts/security_audit.py

# OWASP ZAP scan
docker run -t owasp/zap2docker-stable zap-baseline.py \
  -t http://localhost:8000

# Dependency vulnerability scan
pip install safety
safety check --json
```

### ML Model Validation

```python
# Open Jupyter notebook
jupyter notebook ml_engine/model_training.ipynb

# Run validation cells:
# - Section 12: Model Testing
# - Section 13: Performance Metrics
# - Section 14: Confusion Matrix
```

## âš¡ Performance Optimization

### Backend Optimization

#### 1. Database Query Optimization

```python
# Bad: N+1 queries
incidents = session.query(Incident).all()
for incident in incidents:
    print(incident.user.name)  # Triggers separate query

# Good: Eager loading
incidents = session.query(Incident).options(
    joinedload(Incident.user)
).all()
```

#### 2. Caching Strategy

```python
from functools import lru_cache
from core.state_manager import get_state_manager

# In-memory cache for frequently accessed data
@lru_cache(maxsize=1000)
def get_metric_threshold(metric_name: str):
    return THRESHOLDS.get(metric_name, 80)

# Redis cache for distributed systems
async def get_cached_analysis(prompt: str):
    cache_key = f"llm:{hash(prompt)}"
    cached = await state_mgr.get(cache_key)
    if cached:
        return cached
    
    result = await llm.analyze(prompt)
    await state_mgr.set(cache_key, result, ttl=3600)
    return result
```

#### 3. Connection Pooling

```python
# backend/core/config.py
class Settings(BaseSettings):
    # PostgreSQL
    DB_POOL_SIZE: int = 20
    DB_MAX_OVERFLOW: int = 10
    DB_POOL_TIMEOUT: int = 30
    
    # Redis
    REDIS_MAX_CONNECTIONS: int = 50
```

#### 4. Async Processing

```python
import asyncio

# Bad: Sequential processing
for metric in metrics:
    analyze_metric(metric)

# Good: Concurrent processing
tasks = [analyze_metric(m) for m in metrics]
results = await asyncio.gather(*tasks)
```

### Frontend Optimization

#### 1. Streamlit Caching

```python
import streamlit as st

# Cache expensive computations
@st.cache_data(ttl=300)  # 5 minutes
def load_historical_data(metric_name: str, hours: int):
    return fetch_from_database(metric_name, hours)

# Cache resource initialization
@st.cache_resource
def get_ml_model():
    return load_model("anomaly_detector.pkl")
```

#### 2. Lazy Loading

```python
# Load only when needed
if st.sidebar.button("Show Advanced Analytics"):
    advanced_analytics = load_advanced_module()
    advanced_analytics.render()
```

#### 3. Batch API Requests

```python
# Bad: Multiple requests
cpu = requests.get("/api/v1/metrics/cpu")
memory = requests.get("/api/v1/metrics/memory")
disk = requests.get("/api/v1/metrics/disk")

# Good: Single batch request
all_metrics = requests.get("/api/v1/metrics/all")
```

### ML Model Optimization

#### 1. Model Quantization

```python
from transformers import AutoModelForSequenceClassification
import torch

# Load model with 8-bit quantization
model = AutoModelForSequenceClassification.from_pretrained(
    "distilbert-base-uncased",
    load_in_8bit=True,
    device_map="auto"
)
```

#### 2. Batch Predictions

```python
# Bad: Predict one by one
for data_point in data_points:
    detector.predict_single(data_point)

# Good: Batch prediction
predictions = detector.predict_batch(data_points)
```

#### 3. Model Pruning

```python
import torch.nn.utils.prune as prune

# Prune 30% of weights
prune.l1_unstructured(model.layer, name="weight", amount=0.3)
```

### Monitoring Performance

```python
# Add timing decorators
from functools import wraps
import time

def measure_time(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start = time.time()
        result = await func(*args, **kwargs)
        duration = time.time() - start
        logger.info(f"{func.__name__} took {duration:.2f}s")
        return result
    return wrapper

@measure_time
async def analyze_metrics():
    # Your code here
    pass
```

## ï¿½ Troubleshooting Guide

### Common Issues

#### 1. API Connection Errors

**Problem:** `ConnectionRefusedError` when accessing backend

**Solutions:**

```bash
# Check if backend is running
curl http://localhost:8000/health

# Check Docker containers
docker-compose ps

# View backend logs
docker-compose logs backend

# Restart backend
docker-compose restart backend
```

#### 2. GROQ API Rate Limits

**Problem:** `429 Too Many Requests` from GROQ API

**Solutions:**

```python
# Switch to Ollama for local inference
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Or implement exponential backoff
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
async def call_groq_api(prompt):
    return await groq_client.chat(prompt)
```

#### 3. Database Connection Pool Exhausted

**Problem:** `TimeoutError: QueuePool limit exceeded`

**Solutions:**

```python
# Increase pool size in .env
DB_POOL_SIZE=50
DB_MAX_OVERFLOW=20

# Check for unclosed connections
from sqlalchemy import event

@event.listens_for(Engine, "connect")
def receive_connect(dbapi_conn, connection_record):
    logger.info("Connection opened")

@event.listens_for(Engine, "close")
def receive_close(dbapi_conn, connection_record):
    logger.info("Connection closed")
```

#### 4. High Memory Usage

**Problem:** Backend using excessive memory

**Solutions:**

```bash
# Profile memory usage
pip install memory-profiler
python -m memory_profiler backend/main.py

# Identify memory leaks
python -m pympler.asizeof backend/main.py

# Clear caches periodically
# In backend/core/state_manager.py
async def cleanup_cache():
    await state_mgr.clear_expired()
```

#### 5. Streamlit App Freezing

**Problem:** Dashboard becomes unresponsive

**Solutions:**

```python
# Reduce auto-refresh frequency
st.empty()  # Clear previous widgets
time.sleep(10)  # Increase from 5 seconds

# Limit data points displayed
recent_data = get_recent_data(hours=1)  # Instead of 24 hours

# Use st.spinner for long operations
with st.spinner("Loading data..."):
    data = expensive_operation()
```

#### 6. WebSocket Disconnections

**Problem:** Real-time updates stop working

**Solutions:**

```python
# Add reconnection logic (frontend)
def connect_websocket():
    try:
        ws = websocket.create_connection("ws://localhost:8000/ws")
        return ws
    except:
        time.sleep(5)
        return connect_websocket()  # Retry

# Implement heartbeat (backend)
@router.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    try:
        while True:
            await websocket.send_json({"type": "heartbeat"})
            await asyncio.sleep(30)
    except WebSocketDisconnect:
        logger.info("Client disconnected")
```

### Debugging Tools

```bash
# Enable debug mode
DEBUG=True python backend/main.py

# Check API docs
open http://localhost:8000/docs

# Test WebSocket
python scripts/test_ws_client.py

# View database schema
psql $DATABASE_URL -c "\dt"

# Check Redis keys
redis-cli KEYS '*'

# Monitor logs in real-time
tail -f backend/logs/app.log
```

## ï¿½ Additional Documentation

- **[API Keys Setup Guide](./docs/API_KEYS_SETUP.md)** - Detailed API key configuration
- **[Production Setup](./docs/PRODUCTION_SETUP.md)** - Production deployment checklist
- **[Architecture Deep Dive](./docs/ARCHITECTURE.md)** - System design and patterns
- **[Deployment Checklist](./docs/DEPLOYMENT_CHECKLIST.md)** - Pre/post deployment steps
- **[Quick Start Enhanced](./docs/QUICKSTART_ENHANCED.md)** - Fast setup guide

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

### Development Setup

```bash
# Fork and clone repository
git clone https://github.com/KUNALSHAWW/Real-Time-System-Monitoring-with-AI-Predictions.git
cd Real-Time-System-Monitoring-with-AI-Predictions

# Create feature branch
git checkout -b feature/your-feature-name

# Install development dependencies
pip install -r backend/requirements.txt
pip install -r backend/requirements-dev.txt

# Install pre-commit hooks
pre-commit install
```

### Code Standards

- **Python**: Follow PEP 8, use Black formatter
- **Type Hints**: Required for all functions
- **Docstrings**: Google-style docstrings
- **Tests**: Minimum 80% code coverage

### Pull Request Process

1. **Update Tests**: Add tests for new features
2. **Update Docs**: Document API changes
3. **Run Linters**:
   ```bash
   black backend/ frontend/ ml_engine/
   flake8 backend/ frontend/ ml_engine/
   mypy backend/
   ```
4. **Run Tests**:
   ```bash
   pytest tests/ -v --cov
   ```
5. **Submit PR**: With clear description and screenshots

### Areas to Contribute

- ğŸ› Bug fixes
- âœ¨ New features (AI models, integrations)
- ğŸ“š Documentation improvements
- ğŸ¨ UI/UX enhancements
- ğŸ”§ Performance optimizations
- ğŸŒ Internationalization

## ï¿½ Performance Benchmarks

| Metric | Target | Actual |
|--------|--------|--------|
| API Response Time (p50) | < 100ms | 45ms |
| API Response Time (p99) | < 500ms | 280ms |
| Dashboard Load Time | < 2s | 1.2s |
| Anomaly Detection Latency | < 200ms | 150ms |
| LLM Analysis (GROQ) | < 1s | 650ms |
| WebSocket Latency | < 50ms | 25ms |
| Memory Usage (Backend) | < 512MB | 340MB |
| CPU Usage (Idle) | < 5% | 2.3% |

*Tested on: 4-core CPU, 8GB RAM, SSD storage*

## ğŸ“œ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### What This Means

âœ… **You CAN:**
- Use commercially
- Modify and distribute
- Use privately
- Include in proprietary software

âŒ **You CANNOT:**
- Hold authors liable
- Use trademark without permission

ğŸ“‹ **You MUST:**
- Include original license
- State significant changes

---

## ğŸ‘¨â€ğŸ’» About the Developer

<div align="center">

### Kunal Shaw

**Computer Science Student | Full-Stack Developer | AI/ML Enthusiast**

Passionate about building scalable, user-friendly applications that solve real-world problems. This project demonstrates expertise in:
- **Frontend Development**: Streamlit, Responsive UI/UX, CSS Animations
- **Backend Development**: FastAPI, RESTful APIs, WebSocket
- **AI/ML Integration**: Multi-LLM systems, Anomaly Detection, Forecasting
- **System Architecture**: Microservices, Caching, State Management
- **DevOps**: Docker, CI/CD, Production Deployment

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/kunal-kumar-shaw-443999205)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/KUNALSHAWW)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:cs23b1039@iiitr.ac.in)

**ğŸ“§ Contact**: cs23b1039@iiitr.ac.in  
**ğŸ”— LinkedIn**: [Kunal Kumar Shaw](https://www.linkedin.com/in/kunal-kumar-shaw-443999205)  
**ğŸ’» GitHub**: [@KUNALSHAWW](https://github.com/KUNALSHAWW)

</div>

---

## ğŸ™ Acknowledgments

This project was built using industry-standard technologies and best practices:

### Technologies Used
- **FastAPI** - Modern, fast web framework for building APIs
- **Streamlit** - Fastest way to build data apps
- **Plotly** - Interactive graphing library
- **scikit-learn** - Machine learning library
- **GROQ** - Ultra-fast AI inference
- **Redis** - In-memory data structure store
- **PostgreSQL** - Powerful, open-source database

### Special Thanks
- **IIIT Raichur** - For providing an excellent learning environment
- **Open Source Community** - For the amazing tools and libraries
- **Stack Overflow** - For countless solutions and guidance
- **GitHub** - For hosting and version control

### Inspiration
Built with the goal of making system monitoring accessible to everyone, from experienced DevOps engineers to business managers who need to understand their infrastructure health without technical complexity.

---

## ğŸ“Š Project Statistics

<div align="center">

![Lines of Code](https://img.shields.io/badge/Lines%20of%20Code-15000+-blue)
![Files](https://img.shields.io/badge/Files-50+-green)
![Python Version](https://img.shields.io/badge/Python-3.9%2B-yellow)
![Build Status](https://img.shields.io/badge/Build-Passing-success)
![Code Quality](https://img.shields.io/badge/Code%20Quality-A-brightgreen)

</div>

---

## ğŸŒŸ Show Your Support

If you found this project helpful, please consider:
- â­ **Starring** this repository
- ğŸ› **Reporting bugs** via GitHub Issues
- ğŸ’¡ **Suggesting features** via GitHub Discussions
- ğŸ“¢ **Sharing** with your network
- ğŸ¤ **Contributing** to the codebase

---

<div align="center">

### Made with â¤ï¸ by Kunal Shaw

**"Building technology that makes a difference"**

[![GitHub followers](https://img.shields.io/github/followers/KUNALSHAWW?style=social)](https://github.com/KUNALSHAWW)
[![LinkedIn](https://img.shields.io/badge/Connect-LinkedIn-blue?style=social&logo=linkedin)](https://www.linkedin.com/in/kunal-kumar-shaw-443999205)

**Â© 2024 Kunal Shaw. All Rights Reserved.**

[â¬† Back to Top](#-real-time-system-health-monitor-with-ai-predictions)

</div>

## ğŸ™ Acknowledgments

This project is built with amazing open-source tools:

### Core Technologies
- **[FastAPI](https://fastapi.tiangolo.com/)** - Modern Python web framework
- **[Streamlit](https://streamlit.io/)** - Data app framework
- **[SQLAlchemy](https://www.sqlalchemy.org/)** - SQL toolkit and ORM
- **[Redis](https://redis.io/)** - In-memory data store
- **[PostgreSQL](https://www.postgresql.org/)** - Relational database

### Machine Learning
- **[scikit-learn](https://scikit-learn.org/)** - ML algorithms
- **[PyTorch](https://pytorch.org/)** - Deep learning framework
- **[Hugging Face Transformers](https://huggingface.co/)** - NLP models
- **[Prophet](https://facebook.github.io/prophet/)** - Time-series forecasting
- **[statsmodels](https://www.statsmodels.org/)** - Statistical models

### AI Services
- **[GROQ](https://groq.com/)** - Ultra-fast LLM inference
- **[Ollama](https://ollama.ai/)** - Local LLM runtime
- **[OpenAI](https://openai.com/)** - GPT models

### Infrastructure
- **[Docker](https://www.docker.com/)** - Containerization
- **[Kubernetes](https://kubernetes.io/)** - Container orchestration
- **[Nginx](https://nginx.org/)** - Web server and reverse proxy

Special thanks to all contributors and the open-source community! ğŸ‰

## ğŸ“ Support & Community

### Get Help

- **ğŸ“– Documentation**: [https://docs.systemmonitoring.dev](https://docs.systemmonitoring.dev)
- **ğŸ’¬ Discussions**: [GitHub Discussions](https://github.com/KUNALSHAWW/Real-Time-System-Monitoring-with-AI-Predictions/discussions)
- **ğŸ› Issues**: [GitHub Issues](https://github.com/KUNALSHAWW/Real-Time-System-Monitoring-with-AI-Predictions/issues)

<div align="center">

**Built with â¤ï¸ by the DevOps & SRE Community**

â­ **Star this repo** if you find it helpful!

[Report Bug](https://github.com/KUNALSHAWW/Real-Time-System-Monitoring-with-AI-Predictions/issues) Â· [Request Feature](https://github.com/KUNALSHAWW//issues) Â· [Contributing Guide](CONTRIBUTING.md)

---

**Last Updated:** November 2025  
**Version:** 2.0.0  
**Status:** ğŸŸ¢ Production Ready

</div>
